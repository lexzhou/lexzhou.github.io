---
layout: about
title: About
permalink: /
subtitle: 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  # more_info: >
  #  <p>555 your office number</p>
  #  <p>123 your address street</p>
  #  <p>Your City, State 12345</p>

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a research resident at Microsoft, advised by Dr. [Xing Xie][xxie] and Prof. [Jose Hernandez-Orallo][jhorallo], and an incoming PhD candidate at Princeton University, to be advised by Prof. [Peter Henderson](https://www.peterhenderson.co/) at the [POLARIS Lab](https://www.polarislab.org/). I did my master's in NLP & HCI at the University of Cambridge, supervised by Prof. [Andreas Vlachos][avlachos]. Prior to that, I did my BSc in Data Science at the Universitat Politècnica de València, where I got into research by working with Prof. [Jose Hernandez-Orallo][jhorallo].

I am interested in research about AI Evaluation, social computing, human-AI interactions and AI safety, regularly taking inspiration from psychometrics and cognitive science. At present, I mostly spend my day thinking about (i) designing robust evaluation methods that offer explanatory and predictive power of AI's capabilities and limitations, and (ii) assessing and anticipating societal risks associated with the deployment of AI in the quest of offering actionable insights that translate into policy and design changes to minimise the harms of AI while amplifying their benefits. I am especially intrigued by general-purpose systems like LLMs.

I've spent time in research/consultancy roles on AI Evaluation at Microsoft Research, Meta AI, OpenAI, Krueger AI Safety Lab, VRAIN, and European Commission JRC. My work has been featured in [Nature](https://www.nature.com/articles/d41586-024-03137-3), [Financial Times](https://www.ft.com/content/0876687a-f8b7-4b39-b513-5fee942831e8), [MIT Tech Review](https://mp.weixin.qq.com/s/T2aqVlWePuRfEEuIP5_yqg), [Forbes](https://www.forbes.com/sites/delltechnologies/2024/10/29/steer-your-ai-strategy-straight-amid-the-jagged-frontier/), [IEEE Spectrum](https://spectrum.ieee.org/chatgpt-reliability), [El País](https://english.elpais.com/technology/2024-09-25/new-ai-models-like-chatgpt-pursue-superintelligence-but-cant-be-trusted-even-when-it-comes-to-basic-questions.html), [New Scientists](https://www.newscientist.com/article/2449427-ais-get-worse-at-answering-simple-questions-as-they-get-bigger/), [QbitAI](https://mp.weixin.qq.com/s/VCvkSUdKT7ZgBaeLWKVoTg), [IBM](https://www.ibm.com/blog/llms-and-reliability/), among others.

If you are drawn to everything relevant to AI Evaluation and wanna stay informed, please subscribe our monthly [AI Evaluation Digest][aied] newsletter! If you wanna talk about something I do, feel free to reach out via [email](lexinzhouds@gmail.com) or on [Twitter](https://x.com/lexin_zhou).

[op]: https://www.openphilanthropy.org/
[jhorallo]: https://josephorallo.webs.upv.es/
[avlachos]: https://andreasvlachos.github.io/
[aied]: https://aievaluation.substack.com/
[xxie]: https://scholar.google.com/citations?user=5EQfAFIAAAAJ&hl=en
